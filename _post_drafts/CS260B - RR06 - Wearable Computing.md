---
layout: post
date: 2017-09-17
---

Both of these papers are impressively deep and broad explorations of wearable technology. They address so many concerns, both obvious and not, that they were thrilling to read.

#### Augmented Reality through Wearable Computing
Thad Starner, Steve Mann, Bradley Rhodes, Jeffrey Levine, Jennifer Healey, Dana Kirsch, Rosalind W. Picard, and Alex Pentland
Presence: Teleoperators and Virtual Environments 1997 6:4, 386-398 
http://dx.doi.org/10.1162/pres.1997.6.4.386
http://www.mitpressjournals.org/doi/10.1162/pres.1997.6.4.386

I've seen Thad Starner speak, and in particular I've seen him demonstrate his wearable computing. He was sporting Google Glass at the talk, and his presentation involved one of the most seamless interactions with Google Glass that I've ever seen. He performed a search for a random phrase suggested by the audience and presented the data, and only later revealed that his Glass had helped him. Of course it was in a practiced presentation, but his ability to send commands to his Glass and maintain the flow of conversation was quite good. That is always one of my main concerns when considering augmented reality systems - I imagine a sort of dystopic future where people zone out in the middle of sentences, distracted by something on their AR screen. Actually, I already see this happening when people are interrupted by notifications from their smartwatches: it's brief, but irritating, as their attention is dragged towards whatever is buzzing on their wrist. Even if they dismiss it, the interruption already occurred. When describing the Remembrance Agent, the authors claim users could ignore the data, only attending when they're interested. But I question the likelihood of that. I already get phantom phone buzzes in my pocket, and the effort required to dismiss a notification can be enough to derail my train of thought. I question whether "remember" is the right description for what the RA is helping the user do. Perhaps displaying a data stream supports recognition rather than recall, one of Nielsen's 10 Usability Heuristics. How would this change how people process information?

They did provide some compelling use-cases. I was particularly drawn to the personalized museum visit: how exciting to be able to dig into more details that each person is interested! By combining this with the Sotto Voce project, you could allow people to "look over the shoulder" of someone else as they chased interesting ideas. I also really loved the ability for an engineer to query experts in their company about "How do I reboot a Sun workstation?" Working in industry, this kind of in-house knowledge was crucial to success, and exceedingly hard to come by. (Having said that, I usually needed to go speak to someone in person, because I'd often get sent links that were out of date, incomplete, or just plain wrong...so perhaps even the success of this would rely on there being accurate documentation in the first case, which is extremely unlikely). This use-case in particular reminded me of the Memex from Vannevar Bush. 

The Remembrance Agent personalizes responses.  what does it mean for computer systems to always be reflecting our own thoughts/work/etc back at us? I don't see a discussion of a system explicitly pointing out a question that you're not asking, as an instructor or parent might do. It's the difference between repeatedly googling "why are Conservatives so heartless?" and realizing that the question itsel fis flawed. These systems don't seem to consider that, or provide ways to address the challenge.

I do love the focus on what "computers do well". I think in general this is a useful way to frame the role systems should play in our lives. The use of the word "agent" does imply 'intelligence' or at least something that tries to be intelligent. Eric Horvitz' Principles of Mixed-Initiative User Interfaces identified the importance of "anticipating needs" - but I think this is extremeley difficult to do correctly, and I'm not convinced the RA addresses this challenge. Raskin would say a system like the RA - or anything that adjusts over time - is inhumane: unpredictable and customizable so  you never develop habits.

Finally, I laughed out loud when I saw Fig. 2, with the caption: "Different styles of wearable computing hardware". An image of 6 very similarly-dressed, almost identical body types, seemingly same race, gender? That is not how I would caption that photograph:

!["different styles" of werable computing](https://i.imgur.com/TuD5lki.png)




#### Project Jacquard: Interactive Digital Textiles at Scale
Poupyrev, Ivan, et al. "Project Jacquard: interactive digital textiles at scale." Proceedings of the 2016 CHI Conference on Human Factors in Computing Systems. ACM, 2016.
http://dl.acm.org/citation.cfm?doid=2858036.2858176

Focus on manufacturing affordability/ease (addressing some messiness concerns of Dourish and Bell)

"for designers of those objects, digital sensing and computation become basic properties of the textile materials—like weight, color and elasticity."

Love the details about existing yarn types. Sometimes I think about how these documents will be useful to historians but not always in obvious ways that we think.

Reading papers is frustrating becauase i have to flip back and forth to the citations. PDFs are terrible.

Oh cool they talk about their inspiration! " Project Jacquard was inspired by observing that the structure of woven textiles strongly resembles the structure of the multitouch sensor panels used in today’s mobile phones and tablets with projected capacitive sensing: both are based on grid topology"

list of requirements: daaaaaaaaamn
" we were not aware of existing yarns that could satisfy all these requirements" so we built one motherfuckerssssss

Holy shit this paper.




